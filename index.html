<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Jamest</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Jamest</h1><a id="logo" href="/.">Jamest</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/2019/05/04/EM算法/">EM算法</a></h1><div class="post-meta">2019-05-04</div><div class="post-content"><p>EM算法，即最大期望算法（Expectation-maximization algorithm），是在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型 <strong><font color="red">依赖于无法观测的隐性变量</font></strong>。<br></p></div><p class="readmore"><a href="/2019/05/04/EM算法/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/05/03/降维算法一览/">降维算法一览</a></h1><div class="post-meta">2019-05-03</div><div class="post-content"><p>在机器学习中经常会碰到一些高维的数据集，而在高维数据情形下会出现数据样本稀疏，距离计算等困难，这类问题是所有机器学习方法共同面临的严重问题，称之为 <strong><font color="red">“ 维度灾难 ”</font></strong>。另外在高维特征中容易出现特征之间的线性相关，这也就意味着有的特征是冗余存在的。基于这些问题，降维思想就出现了。<br>降维就是指采用某种映射方法，将原高维空间中的数据点映射到低维度的空间中。通过降维，可以方便数据可视化+数据分析+数据压缩+数据提取等。<br></p></div><p class="readmore"><a href="/2019/05/03/降维算法一览/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/04/29/xgboost-lightgbm调参指南/">xgboost&amp;lightgbm调参指南</a></h1><div class="post-meta">2019-04-29</div><div class="post-content"><p>本文重点阐述了xgboost和lightgbm的主要参数和调参技巧，其理论部分可见<a href="https://hellojamest.github.io/2019/04/24/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" target="_blank" rel="noopener">集成学习</a>,以下内容主要来自<a href="https://xgboost.readthedocs.io/en/latest/parameter.html" target="_blank" rel="noopener">xgboost</a>和<a href="https://lightgbm.readthedocs.io/en/latest/Parameters.html" target="_blank" rel="noopener">LightGBM</a>的官方文档。</p></div><p class="readmore"><a href="/2019/04/29/xgboost-lightgbm调参指南/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/04/24/集成学习/">集成学习</a></h1><div class="post-meta">2019-04-24</div><div class="post-content"><p>集成学习的目的是通过结合多个基学习器的预测结果来改善单个学习器的泛化能力和鲁棒性。<br>目前主流方法有三种：<br>1.Boosting方法：包括Adaboost，GBDT, XGBoost等<br>2.Bagging方法：典型的是Random Forest<br>3.Stacking算法<br></p></div><p class="readmore"><a href="/2019/04/24/集成学习/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/04/23/机器学习基础问题/">机器学习基础概念</a></h1><div class="post-meta">2019-04-23</div><div class="post-content"><p>记录一些常见的机器学习基础概念。<br></p></div><p class="readmore"><a href="/2019/04/23/机器学习基础问题/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/04/23/决策树模型/">决策树模型</a></h1><div class="post-meta">2019-04-23</div><div class="post-content"><p>决策树的目标是从一组样本数据中，根据不同的特征和属性，建立一棵树形的分类结构。<br><strong>决策树的学习本质上是从训练集中归纳出一组分类规则，得到与数据集矛盾较小的决策树，同时具有很好的泛化能力。<font color="red">决策树学习的损失函数通常是正则化的极大似然函数</font></strong>，通常采用启发式方法，近似求解这一最优化问题。<br></p></div><p class="readmore"><a href="/2019/04/23/决策树模型/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/04/22/支持向量机模型/">支持向量机模型</a></h1><div class="post-meta">2019-04-22</div><div class="post-content"><p>支持向量机模型(SVM)是一个二分类模型，基本思想是<strong>求解能够正确划分训练数据集并且几何间隔最大的分离超平面</strong>，其学习策略便是间隔最大化，最终化为一个凸二次规划问题的求解。<br>SVM可分为线性可分支持向量机、线性支持向量机和非线性支持向量机。</p></div><p class="readmore"><a href="/2019/04/22/支持向量机模型/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/04/21/逻辑回归模型/">逻辑回归模型</a></h1><div class="post-meta">2019-04-21</div><div class="post-content"><p>逻辑回归模型是针对线性可分问题的一种易于实现而且性能优异的分类模型。<br><strong>它假设数据服从<font color="red">伯努利分布</font>,通过<font color="red">极大化似然函数</font>的方法，运用<font color="red">梯度下降法</font>来求解参数，来达到将数据二分类的目的。</strong></p></div><p class="readmore"><a href="/2019/04/21/逻辑回归模型/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/04/19/最大熵模型/">最大熵模型</a></h1><div class="post-meta">2019-04-19</div><div class="post-content"><p>最大熵模型是指在满足约束条件的模型集合中选取熵最大的模型，即不确定性最大的模型。<br></p></div><p class="readmore"><a href="/2019/04/19/最大熵模型/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/01/22/hello-world/">Hello World</a></h1><div class="post-meta">2019-01-22</div><div class="post-content"><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p></div><p class="readmore"><a href="/2019/01/22/hello-world/">Read More</a></p></div><nav class="page-navigator"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="http://yoursite.com"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/algorithms/" style="font-size: 15px;">algorithms</a> <a href="/tags/machine-learning/" style="font-size: 15px;">machine learning</a> <a href="/tags/Algorithm-practice/" style="font-size: 15px;">Algorithm practice</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/05/04/EM算法/">EM算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/03/降维算法一览/">降维算法一览</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/29/xgboost-lightgbm调参指南/">xgboost&lightgbm调参指南</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/24/集成学习/">集成学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/23/机器学习基础问题/">机器学习基础概念</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/23/决策树模型/">决策树模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/22/支持向量机模型/">支持向量机模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/21/逻辑回归模型/">逻辑回归模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/19/最大熵模型/">最大熵模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/22/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/helloJamest" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Jamest.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" color="0,0,0" opacity="0.5" zindex="-2" count="50" src="//lib.baomitu.com/canvas-nest.js/2.0.3/canvas-nest.umd.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>